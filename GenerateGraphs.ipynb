{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eceb7f91-63e1-4ddd-ac61-6103070248d5",
   "metadata": {},
   "source": [
    "# Generate Graphs\n",
    "\n",
    "This notebook (and associated data) can be used to generate Biomarker-Biomarker networks as prescribed in [Identifying and Validating Networks of Oncology Biomarkers Mined From the Scientific Literature](https://journals.sagepub.com/doi/full/10.1177/11769351221086441)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6763a2-ac8e-49e9-a8aa-a8626e5cc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install networkx\n",
    "!pip install igraph\n",
    "!pip install leidenalg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b4f06-4a66-45c7-a3b9-6f792b26a4b3",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Global Imports](#globalimports)\n",
    "* [Necessary Functions](#functions)\n",
    "* [Run everything](#run)\n",
    "* [Wrap up](#wrapup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbab6d-0040-4ab9-a88d-e81f670203bc",
   "metadata": {},
   "source": [
    "## Global Imports <a class='anchor' id='globalimports'></a>\n",
    "\n",
    "Generally speaking we will just import modules alongside the function they are used in.\n",
    "\n",
    "However, there are a small number of modules that are used so frequently that we import them here, up front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea61a8-5041-4537-9631-2fa18078ce3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19484379-197f-4014-b438-b01ae6a334b2",
   "metadata": {},
   "source": [
    "## Necessary Functions <a class='anchor' id='functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc08af3-35ad-4212-bfb0-92aff60ddff6",
   "metadata": {},
   "source": [
    "#### LoadRawDataFrames\n",
    "\n",
    "This function loads the relevant data and then cleans each up a little bit.\n",
    "\n",
    "**NCI_Biomarkers.csv** - Contains basic additional metadata (associated organ, biomarker type) for each biomarker.\n",
    "\n",
    "**BiomarkerCancer_Cooccurrences.csv** - Contains data for establishing appearance of biomarker within 20 tokens of a phrase indicative of a specific target cancer. Two specific columns bear further explaination:\n",
    "- Unique Publication Count - Biomarker&Slop: Number of publications in which the focal biomarker appears within within 20 tokens of a phrase indicative of the target cancer.\n",
    "- Unique Publication Count - Biomarker: Number of publications in which the focal biomarker appears.\n",
    "\n",
    "**BiomarkerBiomarker_Cooccurrences_Slop20.csv** - Contains publication identifiers for publications in which the specific pairs of biomarkers appear within 20 tokens of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d1466-1f77-4284-81d8-9ab36ac5ef6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "def LoadRawDataFrames():\n",
    "    df_NCIBiomarkerInfo = pd.read_csv('NCI_Biomarkers.csv')\n",
    "    # Change the formatting of the Organ(s) list.\n",
    "    df_NCIBiomarkerInfo.loc[:,'Organ(s)'] = df_NCIBiomarkerInfo['Organ(s)'].str.split(',').apply(lambda lst:';'.join(sorted(lst)))\n",
    "\n",
    "    df_BiomarkerCancer = pd.read_csv('BiomarkerCancer_Cooccurrences.csv')\n",
    "    # Need to do a little bit of work to turn the Publication IDs string into a list.\n",
    "    df_BiomarkerCancer.loc[:,'Publication IDs'] = df_BiomarkerCancer['Publication IDs'].apply(literal_eval)\n",
    "\n",
    "    # Merge the NCI_Biomarkers metadata into it.\n",
    "    df_BiomarkerCancer = df_BiomarkerCancer.merge(df_NCIBiomarkerInfo, left_on='Biomarker', right_on='Biomarker', how='left')\n",
    "\n",
    "    df_BiomarkerBiomarker = pd.read_csv('BiomarkerBiomarker_Cooccurrences_Slop20.csv')\n",
    "    # Again, do a little bit of work to turn the Publication IDs string into a list.\n",
    "    df_BiomarkerBiomarker.loc[:,'Publication IDs'] = df_BiomarkerBiomarker['Publication IDs'].apply(literal_eval)\n",
    "\n",
    "    return df_NCIBiomarkerInfo, df_BiomarkerCancer, df_BiomarkerBiomarker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe0c84-9569-46f8-84f3-7b315308eb3d",
   "metadata": {},
   "source": [
    "#### AddAvgPubAgeAndSlope\n",
    "\n",
    "Here we have two functions that calculate the average publication age, and publication slope, for Biomarkers. One across all cancers. The other for each cancer separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525d423-b80b-494d-8168-05fd4030f5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This little function takes a list of lists, merges the sublists, then returns the unique elements. \n",
    "import itertools\n",
    "def uniques(series):\n",
    "    lists = series.tolist()\n",
    "    result = [id for id in itertools.chain(*lists)]\n",
    "    return list(set(result))\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Across all cancers\n",
    "def AddAvgPubAgeAndSlope_AllCancers(df,PubIDsColumn):\n",
    "\n",
    "    df_PubYear = pd.read_csv('PublicationYear.csv').set_index('Publication ID')\n",
    "\n",
    "    df_tmp = df.groupby('Biomarker').agg(idset=(PubIDsColumn, uniques)).reset_index()\n",
    "    df_tmp = df_tmp.explode('idset')\n",
    "    df_tmp = df_tmp[df_tmp['idset'].notna()]\n",
    "    df_tmp = df_tmp.merge(df_PubYear, left_on='idset', right_index=True)\n",
    "    df_tmp = df_tmp[df_tmp['Publication Year'].notna()]\n",
    "\n",
    "    df_tmp_MeanPubYear = df_tmp.groupby(['Biomarker'])['Publication Year'].mean().to_frame('Avg Pub Year (all cancers)')\n",
    "\n",
    "    df = df.merge(df_tmp_MeanPubYear, left_on='Biomarker', right_index=True, how='left')\n",
    "\n",
    "    series_tmp = df_tmp.groupby(['Biomarker'])['Publication Year'].apply(list)\n",
    "    \n",
    "    warnings.filterwarnings('ignore', message='Polyfit may be poorly conditioned') # Polyfit throws a lot of repetitive errors re: not trusting the fit when few data.\n",
    "    Biomarker_Slope = {}\n",
    "    for Biomarker,PubYears in series_tmp.items():\n",
    "        X,Y = list(Counter(sorted(PubYears)).keys()), list(Counter(sorted(PubYears)).values())\n",
    "        ScaledSlope = 100.0*np.polyfit(X,Y,1)[0]/np.mean(Y) # The 100.0 is just to produce a reasonable scale.\n",
    "        Biomarker_Slope[Biomarker] = ScaledSlope\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    df_tmp_Biomarker_Slope = pd.DataFrame.from_dict(Biomarker_Slope,orient='index').rename(mapper={0:'Pubs slope (all cancers)'},axis=1)\n",
    "\n",
    "    df = df.merge(df_tmp_Biomarker_Slope, left_on='Biomarker', right_index=True, how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# For the specific cancer. This is essentially the same as above, just with the groupby being executed on 'Cancer' as well.\n",
    "def AddAvgPubAgeAndSlope_CancerSpecific(df,PubIDsColumn):\n",
    "\n",
    "    df_PubYear = pd.read_csv('PublicationYear.csv').set_index('Publication ID')\n",
    "\n",
    "    df_tmp = df.groupby(['Biomarker','Cancer']).agg(idset=(PubIDsColumn, uniques)).reset_index()\n",
    "    df_tmp = df_tmp.explode('idset')\n",
    "    df_tmp = df_tmp[df_tmp['idset'].notna()]\n",
    "    df_tmp = df_tmp.merge(df_PubYear, left_on='idset', right_index=True)\n",
    "    df_tmp = df_tmp[df_tmp['Publication Year'].notna()]\n",
    "\n",
    "    df_tmp_MeanPubYear = df_tmp.groupby(['Biomarker','Cancer'])['Publication Year'].mean().to_frame('Avg Pub Year (this cancer)').reset_index()\n",
    "\n",
    "    df = df.merge(df_tmp_MeanPubYear, left_on=['Biomarker','Cancer'], right_on=['Biomarker','Cancer'], how='left')\n",
    "\n",
    "    series_tmp = df_tmp.groupby(['Biomarker','Cancer'])['Publication Year'].apply(list)\n",
    "\n",
    "    warnings.filterwarnings('ignore', message='Polyfit may be poorly conditioned') # Polyfit throws a lot of repetitive errors re: not trusting the fit when few data.\n",
    "    Biomarker_Slope = {}\n",
    "    for (Biomarker,Cancer),PubYears in series_tmp.items():\n",
    "        X,Y = list(Counter(sorted(PubYears)).keys()), list(Counter(sorted(PubYears)).values())\n",
    "        ScaledSlope = 100.0*np.polyfit(X,Y,1)[0]/np.mean(Y) # The 100.0 is just to produce a reasonable scale.\n",
    "        Biomarker_Slope[(Biomarker,Cancer)] = ScaledSlope\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "    df_tmp_Biomarker_Slope = pd.DataFrame(data={'Pubs slope (this cancer)': list(Biomarker_Slope.values())}, index=pd.MultiIndex.from_tuples(tuples=Biomarker_Slope.keys(), names=['Biomarker','Cancer'])).reset_index()\n",
    "\n",
    "    df = df.merge(df_tmp_Biomarker_Slope, left_on=['Biomarker','Cancer'], right_on=['Biomarker','Cancer'], how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b025b08-9270-4d7d-b33a-4c4cf3aa9bbd",
   "metadata": {},
   "source": [
    "#### Get_CancerBiomarkerPublications\n",
    "\n",
    "This function takes the biomarker - cancer data and selects only the data that falls into the necessary criteria:\n",
    "- Slop 20\n",
    "- Publication count between 5 and 1000.\n",
    "\n",
    "For the \"overall\" case (*i.e.* summing across all cancers) this function handles the necessary merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa81513-7de0-46d4-b796-80bfbce7f45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This just formats nicely the Publication IDs into a link to them in the Dimensions web application.\n",
    "def IDsListToURL(listofIDs,template='https://app.dimensions.ai/discover/publication?search_mode=content&search_text={}',separator='%20OR%20',pattern='{}'):\n",
    "        if template is not None and isinstance(listofIDs, list):\n",
    "            if len(listofIDs)>0:\n",
    "                ids = separator.join([pattern.format(id) for id in listofIDs])\n",
    "                url = template.format(ids)\n",
    "                return url\n",
    "\n",
    "def Get_CancerBiomarkerPublications(df_biomarkercancer,cancer,slop=20,minmax=[5,1000]):\n",
    "    \n",
    "    # The overall network needs to be treated differently.\n",
    "    if cancer==\"Overall\" or cancer is None:\n",
    "        df_biomarkercancer_local = df_biomarkercancer.loc[(df_biomarkercancer['Unique Publication Count - Biomarker']>=minmax[0]) \\\n",
    "                                                          & (df_biomarkercancer['Unique Publication Count - Biomarker']<=minmax[1]) \\\n",
    "                                                          & (df_biomarkercancer['Slop']==slop) \n",
    "                                                          & (df_biomarkercancer['Unique Publication Count - Biomarker&Slop']>0) \\\n",
    "                                                          , ['Biomarker', 'Publication IDs']\n",
    "                                                         ]\n",
    "        # This agg does the merging of the Publication IDs.\n",
    "        df_biomarkercancer_local = df_biomarkercancer_local.groupby('Biomarker').agg(ids=('Publication IDs', uniques)).reset_index().rename(mapper={'ids':'Publication IDs'},axis=1)\n",
    "\n",
    "        # Unfortunately the groupby discards the other columns of data, but we merge it back in below.\n",
    "        df_biomarkercancer_extradata = df_biomarkercancer[['Biomarker', 'Type', 'Organ(s)', 'Avg Pub Year (all cancers)', 'Pubs slope (all cancers)','Unique Publication Count - Biomarker']].drop_duplicates()\n",
    "        df_biomarkercancer_local = df_biomarkercancer_local.merge(df_biomarkercancer_extradata, right_on='Biomarker', left_on='Biomarker', how='left')\n",
    "        df_biomarkercancer_local = df_biomarkercancer_local.rename(mapper={'Unique Publication Count - Biomarker':'# Pubs (all cancers)'},axis=1)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        df_biomarkercancer_local = df_biomarkercancer.loc[(df_biomarkercancer['Unique Publication Count - Biomarker']>=minmax[0]) \\\n",
    "                                                          & (df_biomarkercancer['Unique Publication Count - Biomarker']<=minmax[1]) \\\n",
    "                                                          & (df_biomarkercancer['Slop']==slop) \\\n",
    "                                                          & (df_biomarkercancer['Unique Publication Count - Biomarker&Slop']>0) \\\n",
    "                                                          & (df_biomarkercancer['Cancer']==cancer) \\\n",
    "                                                          , ['Biomarker', 'Type', 'Organ(s)', 'Avg Pub Year (all cancers)', 'Pubs slope (all cancers)', 'Avg Pub Year (this cancer)', 'Pubs slope (this cancer)', 'Publication IDs','Unique Publication Count - Biomarker','Unique Publication Count - Biomarker&Slop']\n",
    "                                                         ]\n",
    "        df_biomarkercancer_local = df_biomarkercancer_local.rename(mapper={'Unique Publication Count - Biomarker&Slop':'# Pubs (this cancer)', 'Unique Publication Count - Biomarker':'# Pubs (all cancers)'},axis=1)\n",
    "\n",
    "        # Does the final 5,1000 filtering.\n",
    "        df_biomarkercancer_local = df_biomarkercancer_local.loc[(df_biomarkercancer_local['# Pubs (this cancer)']>=minmax[0]) \\\n",
    "                                                                & (df_biomarkercancer_local['# Pubs (this cancer)']<=minmax[1]) \\\n",
    "                                                               ]\n",
    "    \n",
    "    df_biomarkercancer_local['Dimensions link'] = df_biomarkercancer_local['Publication IDs'].apply(IDsListToURL)\n",
    "    \n",
    "    return df_biomarkercancer_local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d0178-fb51-44ad-9ede-c6019ac6870c",
   "metadata": {},
   "source": [
    "#### GetCooccurrenceDataFrame\n",
    "\n",
    "This function takes the biomarker-biomarker co-occurrence dataframe and:\n",
    "1. Filters the Publication IDs, leaving only those also identified as relevant to the target cancer.\n",
    "2. Prepare a count of unique publications in which the biomarker-biomarker pair occures *at least twice*.\n",
    "3. Keep only biomarker-biomarker pairs that satisfy the minimum unique publications, and total publications, thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d042a5-ec1f-46f6-9050-26a42f4227d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a little trick that drops elements that appear only once in the list, thus keeping only entries that appear two or more times.\n",
    "def remove_single_count_items(List):\n",
    "    if len(List)>0:\n",
    "        NewList = List\n",
    "        for item in list(set(List)):\n",
    "            NewList.remove(item)\n",
    "        return NewList\n",
    "    else:\n",
    "        return List\n",
    "\n",
    "def GetCooccurrenceDataFrame(df_biomarkerbiomarker,validpublicationset,mincooc_UniquePapers,mincooc_TotalCounts):\n",
    "    # This keeps only Publication IDs that are in the set of publications valid for the target cancer.\n",
    "    df_biomarkerbiomarker.loc[:,'Publication IDs'] = df_biomarkerbiomarker['Publication IDs'].apply(lambda ids: [id for id in ids if id in validpublicationset])\n",
    "\n",
    "    df_biomarkerbiomarker.loc[:,'Total Cooccurrences'] = df_biomarkerbiomarker['Publication IDs'].apply(len)\n",
    "    df_biomarkerbiomarker.loc[:,'Unique Publication Cooccurrences'] = df_biomarkerbiomarker['Publication IDs'].apply(set).apply(len)\n",
    "    \n",
    "    # Captures the number of publications that have at least two co-occurrences for the given biomarker-biomarker pair.\n",
    "    df_biomarkerbiomarker.loc[:,'Unique Cooccurrences > 1'] = df_biomarkerbiomarker['Publication IDs'].apply(remove_single_count_items).apply(set).apply(len)\n",
    "\n",
    "\n",
    "    # Filter on the number of publications w/ at least mincooc_UniquePapers co-occurrences > 1, and at least mincooc_TotalCounts in total.\n",
    "    df_biomarkerbiomarker = df_biomarkerbiomarker.loc[(df_biomarkerbiomarker['Unique Cooccurrences > 1']>=mincooc_UniquePapers) \\\n",
    "                                                      & (df_biomarkerbiomarker['Total Cooccurrences']>=mincooc_TotalCounts)\n",
    "                                                     ]\n",
    "\n",
    "    return df_biomarkerbiomarker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4db007-64fb-42fa-b82e-cd15f8bfc968",
   "metadata": {},
   "source": [
    "#### GetGraphDataFrame\n",
    "\n",
    "This function takes the co-occurrence dataframes (biomarker-cancer, biomarker-biomarker) and produces a dataframe in which each row is, essentially, a link in the network that will eventually be constructed.\n",
    "\n",
    "It generally proceeds as:\n",
    "1. Joins the biomarker-cancer data for each biomarker onto each biomarker column in the biomarker-biomarker data.\n",
    "2. Calculates edge weights.\n",
    "3. Ranks edge weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81861c-163e-4f9b-96d2-97f45a0f85c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This little function takes a list of Publication IDs and returns the average age of those publications.\n",
    "PublicationYearDict = pd.read_csv('PublicationYear.csv').set_index('Publication ID').to_dict()['Publication Year']\n",
    "def AvgPubAge_fr_PubIDList(PublicationIDsList):\n",
    "    PubYearList = [PublicationYearDict[PubID] for PubID in PublicationIDsList if PubID in PublicationYearDict]\n",
    "    if len(PubYearList)>0:\n",
    "        return np.mean(PubYearList)\n",
    "\n",
    "def GetGraphDataFrame(df_biomarkerbiomarker,df_biomarkercancer,targetcancer):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "    \n",
    "        if targetcancer == 'Overall':\n",
    "            df_biomarkercancer['Avg Pub Year (this cancer)'] = df_biomarkercancer['Avg Pub Year (all cancers)']\n",
    "            df_biomarkercancer['Pubs slope (this cancer)'] = df_biomarkercancer['Pubs slope (all cancers)']\n",
    "            df_biomarkercancer['# Pubs (this cancer)'] = df_biomarkercancer['# Pubs (all cancers)']\n",
    "    \n",
    "        df_biomarkercancer = df_biomarkercancer[['Biomarker','# Pubs (this cancer)', 'Avg Pub Year (this cancer)']]\n",
    "        df_biomarkercancer.loc[:,'Biomarker'] = df_biomarkercancer['Biomarker'].str.lower() # have to lower to make it joinable.\n",
    "\n",
    "        # Merge the biomarker-cancer data in for Biomarker 1\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker.merge(df_biomarkercancer, left_on='Biomarker 1', right_on='Biomarker').drop(columns=['Biomarker'])\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.rename(mapper={'# Pubs (this cancer)':'tmp - # Biomarker 1', 'Avg Pub Year (this cancer)':'tmp - age Biomarker 1'},axis=1)\n",
    "        # Merge the biomarker-cancer data in for Biomarker 2\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.merge(df_biomarkercancer, left_on='Biomarker 2', right_on='Biomarker').drop(columns=['Biomarker'])\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.rename(mapper={'# Pubs (this cancer)':'tmp - # Biomarker 2', 'Avg Pub Year (this cancer)':'tmp - age Biomarker 2'},axis=1)\n",
    "\n",
    "        # Makes a column that is [Cancer-Biomarker Count Biomarker 1, Cancer-Biomarker Count Biomarker 2]\n",
    "        df_biomarkerbiomarker_graph.loc[:,'Unique Publication Counts - Cancer'] = df_biomarkerbiomarker_graph.apply(lambda row: [row['tmp - # Biomarker 1'], row['tmp - # Biomarker 2']], axis=1)\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.drop(['tmp - # Biomarker 1','tmp - # Biomarker 2'],axis=1)\n",
    "\n",
    "        # Makes a column that is [Avg Pub Year Biomarker 1, Avg Pub Year Biomarker 2]\n",
    "        df_biomarkerbiomarker_graph.loc[:,'Avg Pub Year of endpoints'] = df_biomarkerbiomarker_graph.apply(lambda row: [row['tmp - age Biomarker 1'], row['tmp - age Biomarker 2']], axis=1)\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.drop(['tmp - age Biomarker 1','tmp - age Biomarker 2'],axis=1)\n",
    "\n",
    "        # Weights are calculated as the number of unique publication co-occurrences of the biomarker-biomarker pair,\n",
    "        # divided by the Unique Publication Counts - Cancer (i.e. fraction of publications)\n",
    "        df_biomarkerbiomarker_graph.loc[:,'Weights'] = df_biomarkerbiomarker_graph.apply(lambda row: [row['Unique Publication Cooccurrences'] / row['Unique Publication Counts - Cancer'][0], row['Unique Publication Cooccurrences'] / row['Unique Publication Counts - Cancer'][1]], axis=1)\n",
    "\n",
    "        # Get the average age of the publications in the link.\n",
    "        df_biomarkerbiomarker_graph['Avg Pub Year (this cancer)'] = df_biomarkerbiomarker_graph['Publication IDs'].apply(AvgPubAge_fr_PubIDList)\n",
    "        \n",
    "        # This gets the Rank of the edge among all of Biomarker 1's edges.\n",
    "        Rank = df_biomarkerbiomarker_graph.groupby('Biomarker 1')['Unique Publication Cooccurrences'].rank(method='min', ascending=False)\n",
    "        Rank.name = 'Ranks - Biomarker 1'\n",
    "        df_biomarkerbiomarker_graph = pd.concat([df_biomarkerbiomarker_graph, Rank], axis = 1)\n",
    "\n",
    "        # This gets the Rank of the edge among all of Biomarker 1's edges.\n",
    "        Rank = df_biomarkerbiomarker_graph.groupby('Biomarker 2')['Unique Publication Cooccurrences'].rank(method='min', ascending=False)\n",
    "        Rank.name = 'Ranks - Biomarker 2'\n",
    "        df_biomarkerbiomarker_graph = pd.concat([df_biomarkerbiomarker_graph, Rank], axis = 1)\n",
    "\n",
    "        df_biomarkerbiomarker_graph.loc[:,'Ranks'] = df_biomarkerbiomarker_graph.apply(lambda row: [int(row['Ranks - Biomarker 1']), int(row['Ranks - Biomarker 2'])], axis=1)\n",
    "        df_biomarkerbiomarker_graph.loc[:,'Best Rank'] = df_biomarkerbiomarker_graph['Ranks'].apply(min) # Will keep only links that are in the top N of at least one biomarker.\n",
    "        df_biomarkerbiomarker_graph = df_biomarkerbiomarker_graph.drop(['Ranks - Biomarker 1','Ranks - Biomarker 2'],axis=1)\n",
    "\n",
    "        return df_biomarkerbiomarker_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d8c9b-aded-4dcb-ba52-70345d2be402",
   "metadata": {},
   "source": [
    "#### CreateGraph\n",
    "\n",
    "This is a very large function that takes the graph dataframe created previously and actually creates the network, adds metadata, *etc*.\n",
    "\n",
    "On top of just generating the network and adding node and edge data, it also executes the leiden clustering algorithm, thus arriving at cluster/community membership of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9e38f-463a-46af-bb4e-a10cc0e68d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import warnings\n",
    "\n",
    "def CreateGraph(df_graph,df_biomarkercancer,maxrank=None):\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # Filter out edges that are outside the Top N of both nodes.\n",
    "        if maxrank is not None:\n",
    "            df_graph = df_graph.loc[df_graph['Best Rank'].apply(lambda r: r<maxrank),:]\n",
    "\n",
    "        # Set a single valued weight\n",
    "        df_graph.loc[:,'Weight'] = df_graph['Weights'].apply(lambda w: w[0])\n",
    "\n",
    "        # Generate the Dimensions links.\n",
    "        df_graph.loc[:,'Dimensions Link'] = df_graph['Publication IDs'].apply(IDsListToURL)\n",
    "\n",
    "        # To make it easier to align naming for final figures. \n",
    "        EdgeMetadataColumns = {'Weight':'Weight','Best Rank':'Best Rank','Unique Cooccurrences > 1':'# Pubs w/ >1 co-mention',\n",
    "                               'Total Cooccurrences':'# co-mentions','Dimensions Link':'Dimensions link', 'Publication IDs': 'Publication IDs', \n",
    "                               'Avg Pub Year of endpoints':'Avg Pub Year of endpoints', 'Avg Pub Year (this cancer)':'Avg Pub Year (this cancer)'\n",
    "                              }\n",
    "\n",
    "        df_graph = df_graph.rename(mapper=EdgeMetadataColumns,axis=1)\n",
    "\n",
    "        # Generate the networkx Graph object.\n",
    "        G = nx.from_pandas_edgelist(df_graph,'Biomarker 1','Biomarker 2', edge_attr=list(EdgeMetadataColumns.values()))\n",
    "\n",
    "        # The next several lines are for adding the node metadata.\n",
    "        AllBiomarkersPresent = set(df_graph['Biomarker 1'].unique()) | set(df_graph['Biomarker 2'].unique())\n",
    "        df_AllBiomarkersPresent = pd.DataFrame(list(AllBiomarkersPresent),columns=['Biomarker'])\n",
    "        df_AllBiomarkersPresent.loc[:,'Biomarker'] = df_AllBiomarkersPresent.loc[:,'Biomarker'].str.lower()\n",
    "        df_AllBiomarkersPresent = df_AllBiomarkersPresent.set_index('Biomarker')\n",
    "\n",
    "        df_biomarkercancer.loc[:,'Biomarker'] = df_biomarkercancer.loc[:,'Biomarker'].str.lower()\n",
    "        df_biomarkercancer = df_biomarkercancer.set_index('Biomarker')\n",
    "\n",
    "        df_NodeMetadata = df_AllBiomarkersPresent.merge(df_biomarkercancer,left_index=True,right_index=True,how='left')\n",
    "        df_NodeMetadata = df_NodeMetadata.drop(['Publication IDs'],axis=1).reset_index().drop_duplicates(keep='first').set_index('Biomarker')\n",
    "\n",
    "        nx.set_node_attributes(G, values=df_NodeMetadata.to_dict(orient='index'))\n",
    "\n",
    "        # An igraph version of the network is required for leidenalg.\n",
    "        G_igraph = ig.Graph.TupleList([(e[0], e[1], e[2]['Weight']) for e in G.edges.data()], directed=False, weights=True)\n",
    "        Partition = la.find_partition(G_igraph, la.ModularityVertexPartition, seed=411966)\n",
    "\n",
    "        Partition_Optimiser = la.Optimiser()\n",
    "        Partition_Optimiser.set_rng_seed(17041967)\n",
    "        Partition_Result = Partition_Optimiser.optimise_partition(Partition, n_iterations=1000)\n",
    "\n",
    "        # Add the partition result to the network nodes.\n",
    "        df_NodeClusters = pd.DataFrame([{'Biomarker':node['name'],'ClusterID':index} for index, subgraph in enumerate(Partition.subgraphs()) for node in subgraph.vs()])\n",
    "        NodeClusters = df_NodeClusters.set_index('Biomarker').astype('str').to_dict()['ClusterID']\n",
    "        nx.set_node_attributes(G, NodeClusters, 'ClusterID')\n",
    "\n",
    "        # Add betweenness centrality too.\n",
    "        BetweennessCentrality = nx.betweenness_centrality(G)\n",
    "        nx.set_node_attributes(G, BetweennessCentrality, 'Betweenness')\n",
    "\n",
    "        # If both ends of an edge are in the same cluster, label the edge as internal.\n",
    "        for edge in G.edges(data=True):\n",
    "            G[edge[0]][edge[1]].update(internal_cluster_edge=(NodeClusters[edge[0]]==NodeClusters[edge[1]]))\n",
    "        for edge in G.edges:\n",
    "            G.edges[edge]['Within Cluster'] = G.edges[edge]['internal_cluster_edge']\n",
    "            del G.edges[edge]['internal_cluster_edge']\n",
    "\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2f6a6-ecc8-462d-83b6-1e9c8d4e36e8",
   "metadata": {},
   "source": [
    "#### AddAnnotationDataToGraph\n",
    "\n",
    "This function adds annotations to the nodes and edges of the graph.\n",
    "\n",
    "Specifically, it adds to each node:\n",
    "* The LC pathway networks in which the node is present.\n",
    "* The interaction networks in which the node is present.\n",
    "* A link potential GeneCard page(s) for the biomarker.\n",
    "* A link potential Uniprot page(s) for the biomarker.\n",
    "\n",
    "And for each edge:\n",
    "* Whether or not the edge appears in at least one LC pathway network.\n",
    "* The interaction networks in which the edge is appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b449885-d96c-4150-a211-49493197e48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# This just unzips the LCpathways_edgeData.jsonl (that is too large for github in its raw form.)\n",
    "with zipfile.ZipFile('InteractionNetworks_edgeData.zip', 'r') as archive:\n",
    "    for file in archive.namelist():\n",
    "        unzipped = open('./InteractionNetworks_edgeData.jsonl', 'w')\n",
    "        unzipped.write(archive.read(file).decode('utf-8'))\n",
    "        unzipped.close()\n",
    "\n",
    "import json\n",
    "def LoadAnnotationData():\n",
    "    with open('LCpathways_nodeData.json','r') as infile:\n",
    "        lcpathways_nodedata = json.loads(infile.read())\n",
    "\n",
    "    lcpathways_edgedata = {}\n",
    "    with open('LCpathways_edgeData.jsonl','r') as infile:\n",
    "        for jsonl_line in infile.readlines():\n",
    "            entry = json.loads(jsonl_line)\n",
    "            key = frozenset(entry['InteractionTuple'])\n",
    "            data = entry['InteractionData']\n",
    "            lcpathways_edgedata[key] = data\n",
    "\n",
    "    with open('InteractionNetworks_nodeData.json','r') as infile:\n",
    "        interactionnetworks_nodedata = json.loads(infile.read())\n",
    "\n",
    "    interactionnetworks_edgedata = {}\n",
    "    with open('InteractionNetworks_edgeData.jsonl','r') as infile:\n",
    "        for jsonl_line in infile.readlines():\n",
    "            entry = json.loads(jsonl_line)\n",
    "            key = frozenset(entry['InteractionTuple'])\n",
    "            data = entry['InteractionData']\n",
    "            interactionnetworks_edgedata[key] = data\n",
    "    \n",
    "    return lcpathways_nodedata, lcpathways_edgedata, interactionnetworks_nodedata, interactionnetworks_edgedata\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "def AddAnnotationDataToGraph(Graph):\n",
    "    \n",
    "    LCpathways_nodeData, LCpathways_edgeData, InteractionNetworks_nodeData, InteractionNetworks_edgeData = LoadAnnotationData()\n",
    "    \n",
    "    # Note that these are done in an undirected manner.\n",
    "    for edge in list(Graph.edges):\n",
    "        if edge[0] in LCpathways_nodeData and edge[1] in LCpathways_nodeData:\n",
    "            if frozenset(edge) in LCpathways_edgeData:\n",
    "                Graph.edges[edge]['Present in'] = ['LCpathways']\n",
    "        if edge[0] in InteractionNetworks_nodeData and edge[1] in InteractionNetworks_nodeData:\n",
    "            if frozenset(edge) in InteractionNetworks_edgeData:\n",
    "                try:\n",
    "                    Graph.edges[edge]['Present in'].extend(InteractionNetworks_edgeData[frozenset(edge)]['PresentIn'])\n",
    "                except:\n",
    "                    Graph.edges[edge]['Present in'] = InteractionNetworks_edgeData[frozenset(edge)]['PresentIn']\n",
    "\n",
    "    for nodeName in list(Graph.nodes):\n",
    "        if nodeName in LCpathways_nodeData:\n",
    "            Graph.nodes[nodeName]['Present in'] = ['LCpathways']\n",
    "        if nodeName in InteractionNetworks_nodeData:\n",
    "            try:\n",
    "                Graph.nodes[nodeName]['Present in'].extend(InteractionNetworks_nodeData[nodeName]['PresentIn'])\n",
    "            except:\n",
    "                Graph.nodes[nodeName]['Present in'] = InteractionNetworks_nodeData[nodeName]['PresentIn']\n",
    "\n",
    "        # Note that these are just search results. Because not every Biomarker will appear in either GeneCard and/or Uniprot\n",
    "        GeneCardQuery = {'queryString':nodeName}\n",
    "        Graph.nodes[nodeName]['GeneCard Results'] = f'https://www.genecards.org/Search/Keyword?{urlencode(GeneCardQuery)}'\n",
    "        Graph.nodes[nodeName]['Uniprot Results'] = f'https://www.uniprot.org/uniprot/?query=gene:%22{\"+\".join(nodeName.split())}%22+organism%3A%22Homo+sapiens+%28Human%29+%5B9606%5D%22&sort=score'\n",
    "    \n",
    "    return Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a730a-3b01-4283-b06d-2995a9bd0c8b",
   "metadata": {},
   "source": [
    "## Run everything <a class='anchor' id='run'></a>\n",
    "\n",
    "This runs all of the previous pieces in order, for each cancer type.\n",
    "\n",
    "Specifically:\n",
    "1. Loads the data from csvs.\n",
    "1. Processes the biomarker-cancer co-occurrence data.\n",
    "    * And subsequently extracting valid publication ids for the target cancer.\n",
    "1. Process the biomarker-biomarker co-occurrence data.\n",
    "1. Transform the processed biomarker-biomarker co-occurrence data into an \"edge-list\" dataframe.\n",
    "1. Build the network from \"edge-list\" dataframe.\n",
    "    * Also calculate network specific metric (*ex.* cluster, centrality)\n",
    "1. Add the annotation data to the nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876614a6-5dc1-4923-90a8-b4d5c24a36df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Slop = 20 # Value used in publication. Note that this does not get actively used, but rather slop is fixed via the input file containing only data for slop 20.\n",
    "Cancer_Slop = 20 # Value used in publication.\n",
    "MinimumUniquePaperCooccurrence = 2 # Value used in publication.\n",
    "MinimumTotalCooccurrence = 4 # Value used in publication.\n",
    "EdgeMaxRank=5 # Value used in publication.\n",
    "\n",
    "CancersList = ['Bladder','Breast','Colorectal','Lung','Prostate','Renal'] # The 6 target cancer types\n",
    "CancersList.append('Overall') # Plus all 6 together.\n",
    "\n",
    "Graphs = {} # Dict that will hold all of the graphs.\n",
    "\n",
    "for TargetCancer in CancersList:\n",
    "    df_NCIBiomarkerInfo, df_BiomarkerCancer, df_BiomarkerBiomarker = LoadRawDataFrames() # Load the necessary data from csvs\n",
    "\n",
    "    df_BiomarkerCancer = AddAvgPubAgeAndSlope_AllCancers(df_BiomarkerCancer,'Publication IDs')\n",
    "    if TargetCancer != 'Overall': # For overall, doing these numbers cancer specific is redundant.\n",
    "        df_BiomarkerCancer = AddAvgPubAgeAndSlope_CancerSpecific(df_BiomarkerCancer,'Publication IDs')\n",
    "\n",
    "    df_BiomarkerCancer_TargetCancer = Get_CancerBiomarkerPublications(df_BiomarkerCancer,TargetCancer,Cancer_Slop,[5,1000]) # Process the biomarker-cancer data for the TargetCancer.\n",
    "    ValidPublicationSet_TargetCancer = df_BiomarkerCancer_TargetCancer['Publication IDs'].aggregate(uniques) # Get the valid publication ids for the the TargetCancer.\n",
    "    \n",
    "    # Put together the biomarker-biomarker co-occurrence data.\n",
    "    df_Cooccurrences_TargetCancer = GetCooccurrenceDataFrame(df_BiomarkerBiomarker,ValidPublicationSet_TargetCancer,MinimumUniquePaperCooccurrence,MinimumTotalCooccurrence)\n",
    "\n",
    "    # Get the graph dataframe.\n",
    "    df_Graph_TargetCancer = GetGraphDataFrame(df_Cooccurrences_TargetCancer,df_BiomarkerCancer_TargetCancer,TargetCancer)\n",
    "\n",
    "    # Create the graph.\n",
    "    G = CreateGraph(df_Graph_TargetCancer,df_BiomarkerCancer_TargetCancer,maxrank=EdgeMaxRank)\n",
    "\n",
    "    # Add annotation data to the graph.\n",
    "    G = AddAnnotationDataToGraph(G)\n",
    "    \n",
    "    Graphs[TargetCancer] = G\n",
    "    \n",
    "    print('{}\\t{}'.format(TargetCancer,nx.info(G))) # Print the graph summary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4bd13d-6ee3-4a89-94f9-449fb82844c4",
   "metadata": {},
   "source": [
    "## Wrap up <a class='anchor' id='wrapup'></a>\n",
    "\n",
    "At this point the Graphs dict contains the graph for each cancer, plus overall. These can, for example, be put down to disk using the appropriate [networkx write](https://networkx.org/documentation/stable/reference/readwrite/index.html) command for the format you desire the graphs to be saved in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
